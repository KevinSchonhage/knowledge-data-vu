{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a9cab90",
   "metadata": {},
   "source": [
    "# Integration and Visualization\n",
    "- YOUR NAME: Kevin Schönhage\n",
    "- YOUR VUNetID: OMN496\n",
    "\n",
    "(If you do not provide your NAME and VUNetID we will not accept your submission.)\n",
    "\n",
    "**To hand in: one zip file, containing...**\n",
    "- this file, with completed tasks\n",
    "- the ontology you made in the previous assignment (Task 1)\n",
    "- an ontology you found on the web (Task 1)\n",
    "- an integrated ontology (`mapping.ttl`) (Task 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a529e5c1",
   "metadata": {},
   "source": [
    "## Task 1 (20 Points):  Integrating ontologies in Protégé\n",
    "Take the ontology you built for Module 4 (let’s call it ontology A), and find either a fellow student with a similar ontology or an ontology on the web on similar domain. That will be our ontology B. \n",
    "\n",
    "Create an empty ontology in Protégé (ontology C), and import both ontologies. \n",
    "\n",
    "Define at least 6 mappings as following:\n",
    "\n",
    "-    1 mapping between a class from A and a class from B using rdfs:subClassOf \n",
    "-    1 mapping between a class from A and a class from B using owl:equivalentClass\n",
    "-    1 mapping between a property from A and a property from B using rdfs:subPropertyOf\n",
    "-    1 mapping between a property from A and a property from B using either owl:equivalentProperty, owl:disjointProperty, owl:inverseOf, or owl:propertyChainAxiom\n",
    "-    1 mapping between an individual from A and an individual from B using owl:differentFrom\n",
    "-    1 mapping between an individual from A and an individual from B using owl:sameAs \n",
    "\n",
    "The combined ontology should be **consistent**.\n",
    "\n",
    "Save the ontology as Turtle, where the filename is ‘`mapping.ttl`’\n",
    "\n",
    "**Submit all three ontologies together with this assignment, leaving preserved the original file names of the ontologies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd2cfdeb",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'mapping.ttl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmapping.ttl\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m.read())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'mapping.ttl'"
     ]
    }
   ],
   "source": [
    "print(open('mapping.ttl').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efca5acc",
   "metadata": {},
   "source": [
    "## Task 2 (10 Points):  Explain your mapping\n",
    "\n",
    "Please explain and motivate the mapping you made in the previous question in a few sentences in the text field below :\n",
    "\n",
    "I created a new ontology mapping.ttl which integrates my VU ontology (A) with the W3C ORG and FOAF vocabularies (B).\n",
    "I defined six mappings:\n",
    "\n",
    "• vu:Lecturer rdfs:subClassOf foaf:Person\n",
    "\n",
    "• vu:Department owl:equivalentClass org:OrganizationalUnit\n",
    "\n",
    "• vu:partOf rdfs:subPropertyOf org:subOrganizationOf\n",
    "\n",
    "• vu:belongsTo owl:inverseOf org:hasUnit\n",
    "\n",
    "• vu:DrSmith owl:sameAs vu:DrJones\n",
    "\n",
    "• vu:VU owl:differentFrom vu:UvA\n",
    "\n",
    "After running the HermiT reasoner, the ontology was consistent.\n",
    "The mappings successfully connect semantically related classes, properties, and individuals across the ontologies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4436005d",
   "metadata": {},
   "source": [
    "## Task 3 (20 points). From SPARQL to DataFrame\n",
    "\n",
    "For the next few tasks we are going to store the results from our queries in a [Pandas DataFrame](https://pandas.pydata.org), making it easier to perform further data processing on the results. To accomplish this, write a procedure to execute the query and to convert the results into a dataframe. \n",
    "\n",
    "To help you on your way, we have already written the main procedure `table_from_query/2` and the helper function `cast/1` which converts the raw values to the appropriate Python objects. Your task is to write the two missing procedures: `execute_query/2` and `create_dataframe/1`. *HINT: revisit assignment 3 if you are unsure where to start*.\n",
    "\n",
    "Please run the next two cells to import the necessary dependencies and to activate the helper procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d96af3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8441f44-4d4e-4a55-8264-b0eb6a7da7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast(value):\n",
    "    \"\"\" Cast the value from a SPARQL result to an appropriate Python object.\n",
    "        The expected input is a dictionary with at least the keys 'type' and 'value'.\n",
    "    \"\"\"\n",
    "    v = value['value']\n",
    "    if value['type'] in ['literal', 'typed-literal'] and 'datatype' in value.keys():\n",
    "        dtype = URIRef(value['datatype'])\n",
    "        if any(d in dtype for d in ('integer', 'long', 'int', 'short', 'byte')):\n",
    "            return int(v)\n",
    "        if any(d in dtype for d in ('decimal', 'float', 'double')):\n",
    "            return float(v)\n",
    "\n",
    "    # fallback to string\n",
    "    return str(v)\n",
    "\n",
    "def table_from_query(endpoint, query):\n",
    "    \"\"\" Execute a query on an endpoint and return the results as a dataframe.\n",
    "    \"\"\"\n",
    "    query_results = execute_query(endpoint, query)\n",
    "    dataframe = create_dataframe(query_results)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd362085-27ae-401d-a0f4-df1a40307a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_query(endpoint_url, query):\n",
    "    sparql = SPARQLWrapper(endpoint_url)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    return sparql.query().convert()\n",
    "\n",
    "def create_dataframe(results):\n",
    "    cols = results['head']['vars']\n",
    "    rows = []\n",
    "    for b in results['results']['bindings']:\n",
    "        row = []\n",
    "        for c in cols:\n",
    "            row.append(cast(b[c]) if c in b else None)   # << hier de juiste binding casten\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows, columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f999b0-87a4-4dfa-ac96-6df82126b928",
   "metadata": {},
   "source": [
    "To test your code, we ask you to create a dataframe about teachers and their course load. We will use the data in `vuDataset.ttl`, which must be imported in GraphDB as a new repository called `repo-vu`. Use the following endpoint and query for this purpose.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f02d84fe-b312-4eb9-b963-933a1e33365a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'URIRef' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      1\u001b[39m sparql_endpoint = \u001b[33m\"\u001b[39m\u001b[33mhttp://DESKTOP-GNHLHJC:7200/repositories/knowledge-data-vu\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      2\u001b[39m sparql_query = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33mPREFIX vu: <http://example.org/vu/>\u001b[39m\n\u001b[32m      4\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m      7\u001b[39m \u001b[33m} GROUP BY ?teacher\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m courseload = \u001b[43mtable_from_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparql_endpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparql_query\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(courseload)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mtable_from_query\u001b[39m\u001b[34m(endpoint, query)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\" Execute a query on an endpoint and return the results as a dataframe.\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     19\u001b[39m query_results = execute_query(endpoint, query)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m dataframe = \u001b[43mcreate_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m dataframe\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mcreate_dataframe\u001b[39m\u001b[34m(results)\u001b[39m\n\u001b[32m     11\u001b[39m     row = []\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m cols:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m         row.append(\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m b \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)   \u001b[38;5;66;03m# << hier de juiste binding casten\u001b[39;00m\n\u001b[32m     14\u001b[39m     rows.append(row)\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m pd.DataFrame(rows, columns=cols)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mcast\u001b[39m\u001b[34m(value)\u001b[39m\n\u001b[32m      5\u001b[39m v = value[\u001b[33m'\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m value[\u001b[33m'\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mliteral\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtyped-literal\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mdatatype\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m value.keys():\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     dtype = \u001b[43mURIRef\u001b[49m(value[\u001b[33m'\u001b[39m\u001b[33mdatatype\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(d \u001b[38;5;129;01min\u001b[39;00m dtype \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m'\u001b[39m\u001b[33minteger\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlong\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mint\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mshort\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mbyte\u001b[39m\u001b[33m'\u001b[39m)):\n\u001b[32m      9\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(v)\n",
      "\u001b[31mNameError\u001b[39m: name 'URIRef' is not defined"
     ]
    }
   ],
   "source": [
    "sparql_endpoint = \"http://DESKTOP-GNHLHJC:7200/repositories/knowledge-data-vu\"\n",
    "sparql_query = \"\"\"\n",
    "PREFIX vu: <http://example.org/vu/>\n",
    "\n",
    "SELECT ?teacher (COUNT(*) as ?courses) {\n",
    "    ?teacher vu:teaches ?o .\n",
    "} GROUP BY ?teacher\n",
    "\"\"\"\n",
    "\n",
    "courseload = table_from_query(sparql_endpoint, sparql_query)\n",
    "print(courseload)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b548c993-be1b-4aa6-9349-b25df09eafbf",
   "metadata": {},
   "source": [
    "## Task 4 (20 points) - Data visualization\n",
    "\n",
    "Visualizing (parts of) the data can help us gain a better understanding of what we are dealing with. Now that the data is stored as a dataframe, we can use a library like `matplotlib` to create a variety of helpful plots. To illustrate this, run the following cells to install and import the library, and to generate a pie plot from our dataframe about course loads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53d1a6b1-3ea8-4c9f-947f-c9cad81e401a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\kevin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\kevin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.10.6)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\kevin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (1.26.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kevin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kevin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\kevin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\kevin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kevin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\kevin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\kevin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kevin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\kevin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\kevin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kevin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\Kevin\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "24005004-e1f0-41a2-9c9a-0f938c287287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e688426",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'courseload' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Pandas visualization\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mcourseload\u001b[49m.set_index(\u001b[33m'\u001b[39m\u001b[33mteacher\u001b[39m\u001b[33m'\u001b[39m, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      3\u001b[39m courseload[\u001b[33m'\u001b[39m\u001b[33mcourses\u001b[39m\u001b[33m'\u001b[39m].plot.pie()\n",
      "\u001b[31mNameError\u001b[39m: name 'courseload' is not defined"
     ]
    }
   ],
   "source": [
    "# Pandas visualization\n",
    "courseload.set_index('teacher', inplace=True)\n",
    "courseload['courses'].plot.pie()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fb80f3-2e19-464e-a844-94b51cc7feb6",
   "metadata": {},
   "source": [
    "## Task 4a (10 points): Make a horizontal bar chart (with suitable labels and title) from the `courseload` dataframe\n",
    "\n",
    "There are many different kinds of plots that we can make. Please look at [the Pandas wiki](https://pandas.pydata.org/docs/user_guide/visualization.html) to get an idea on what is possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5497c244",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mplt\u001b[49m.figure(figsize=(\u001b[32m8\u001b[39m,\u001b[32m4\u001b[39m))\n\u001b[32m      2\u001b[39m plt.barh(courseload[\u001b[33m'\u001b[39m\u001b[33mteacher_label\u001b[39m\u001b[33m'\u001b[39m], courseload[\u001b[33m'\u001b[39m\u001b[33mcourses\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      3\u001b[39m plt.title(\u001b[33m'\u001b[39m\u001b[33mNumber of courses per teacher\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.barh(courseload['teacher_label'], courseload['courses'])\n",
    "plt.title('Number of courses per teacher')\n",
    "plt.xlabel('# Courses')\n",
    "plt.ylabel('Teacher')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36374e09-d1a9-4415-8513-9792e0db56bd",
   "metadata": {},
   "source": [
    "## Task 4b (10 points): Write a new SPARQL query for DBpedia and create an interesting chart from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b9821b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133b64a6",
   "metadata": {},
   "source": [
    "## Task 5 (10 points). Conditional styling\n",
    "\n",
    "Below is a query to find all EU countries and their surface area in $m^2$. Below that is some code that adds some colour to the resulting table.\n",
    "\n",
    "\n",
    "We ask you to update the query and code below to add a new column that shows the percentage of the country's area that is water.\n",
    "The background color of this column must depend on this percentage: it should be greener if more of the country is land, and bluer if more of the country is water."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3758ff25",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = \"http://dbpedia.org/sparql\"\n",
    "query = \"\"\"\n",
    "PREFIX dct: <http://purl.org/dc/terms/>\n",
    "PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "PREFIX yago: <http://dbpedia.org/class/yago/>\n",
    "\n",
    "SELECT DISTINCT ?name ?area_100k_km2 ?giniCoefficient \n",
    "WHERE { \n",
    "    ?country \n",
    "        a yago:WikicatMemberStatesOfTheEuropeanUnion ;\n",
    "        dbo:area ?area ; # area is stated in m^2\n",
    "        dbo:giniCoefficient ?giniCoefficient ;\n",
    "        rdfs:label ?name. \n",
    "    \n",
    "    BIND (ROUND(?area/100000000000) AS ?area_100k_km2)\n",
    "    FILTER(LANG(?name) = 'en')\n",
    "}\n",
    "ORDER BY DESC(?area_100k_km2)\n",
    "LIMIT 50\"\"\"\n",
    "\n",
    "dbpedia_countries = table_from_query(endpoint, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5be1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Styling: https://pandas.pydata.org/docs/user_guide/style.html\n",
    "# Using CSS Hue-Saturation-Level colors: https://www.w3schools.com/colors/colors_hsl.asp\n",
    "\n",
    "def gini_color(gini):\n",
    "    return f'background: hsl({100 - gini}, 100%, 50%)' \n",
    "\n",
    "dbpedia_countries.style \\\n",
    "    .map(gini_color, subset=(slice(None), \"giniCoefficient\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e178e65c",
   "metadata": {},
   "source": [
    "# Map Visualizations\n",
    "\n",
    "Below is a query to find all EU capitals, together with their coordinates. The results are drawn on a map using the library `folium`. \n",
    "\n",
    "First run the following cells to install and import the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0028de89",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961f68dc-52a1-4128-9464-584f04ddf34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349978e1-9f78-43a8-89ef-312333b89c17",
   "metadata": {},
   "source": [
    "# Task 6 (20 points) - Population counts\n",
    "\n",
    "We ask you to update the query and code below to make the markers (circles) scale with the population of the capital (but keep it readable!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d8d2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = \"http://query.wikidata.org/sparql\"\n",
    "query = \"\"\"\n",
    "SELECT ?capitalLabel ?coords \n",
    "WHERE {\n",
    "    ?country\n",
    "        wdt:P463 wd:Q458 ; # member of: European Union\n",
    "        wdt:P36 ?capital . # capital: ?capital\n",
    "        \n",
    "    ?capital \n",
    "        wdt:P625 ?coords . # coordinate location: ?coords\n",
    "    \n",
    "    # Using Wikidata-only label service\n",
    "    SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "}\"\"\"\n",
    "\n",
    "capitals = table_from_query(endpoint, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ded7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract latitude and longitude from coordinates in Well-Known Text (WKT) format\n",
    "capitals_coords = capitals.join(capitals.coords.str.extract('Point\\\\((?P<lon>\\\\S+) (?P<lat>\\\\S+)\\\\)').astype(float))\n",
    "\n",
    "middle = [capitals_coords['lat'].mean(), capitals_coords['lon'].mean()]\n",
    "m = folium.Map(location=middle, zoom_start=4)\n",
    "for _, row in capitals_coords.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row['lat'], row['lon']],\n",
    "        radius= 20,\n",
    "        popup= row['capitalLabel'],\n",
    "        color=\"#3186cc\",\n",
    "        fill=True,\n",
    "        fill_color=\"#3186cc\",\n",
    "    ).add_to(m)\n",
    "\n",
    "m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
